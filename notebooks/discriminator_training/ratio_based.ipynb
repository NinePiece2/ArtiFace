{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.environ['DATASET_PATH']\n",
    "image_files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.jpg')]\n",
    "\n",
    "EPOCHS = 1000\n",
    "NOISE_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX_SIZE = 10000\n",
    "\n",
    "# Select percentage of data to use in each epoch\n",
    "RANDOM_SELECT = 0.5\n",
    "\n",
    "DISCRIMINATOR_TRAINING_RATIO = 5\n",
    "\n",
    "INTERVAL = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(128, 128, 3,)),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        4864      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 131073    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 340,865\n",
      "Trainable params: 340,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(32*32*512, use_bias=False, input_shape=(NOISE_DIM,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Reshape((32, 32, 512)),\n",
    "        layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 524288)            52428800  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 524288)           2097152   \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 524288)            0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 256)      3276800   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 64, 64, 128)      819200    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 128, 128, 64)     204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128, 128, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 128, 128, 3)      4800      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,833,344\n",
      "Trainable params: 57,783,872\n",
      "Non-trainable params: 1,049,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RESUME = False\n",
    "epoch = 0\n",
    "\n",
    "if(TRAINING_RESUME):\n",
    "    generator.load_weights(os.path.join(os.environ['CHECKPOINT_PATH'], f\"generator_ratio_based_{epoch}.h5\"))\n",
    "    discriminator.load_weights(os.path.join(os.environ['CHECKPOINT_PATH'], f\"discriminator_ratio_based_{epoch}.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discriminator setup\n",
    "discriminator.compile(optimizer=optimizer, loss=loss_object, metrics=['accuracy'])\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator setup\n",
    "noise = layers.Input(shape=(NOISE_DIM,))\n",
    "image = generator(noise)\n",
    "\n",
    "## Combined model\n",
    "validity = discriminator(image)\n",
    "combined = tf.keras.Model(noise, validity)\n",
    "combined.compile(optimizer=optimizer, loss=loss_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train(epoch):\n",
    "    return epoch % DISCRIMINATOR_TRAINING_RATIO == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(epoch):\n",
    "    noise = np.random.normal(0, 1, (1, NOISE_DIM))\n",
    "\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig = gen_imgs[0]\n",
    "    im = Image.fromarray((fig * 255).astype(np.uint8))\n",
    "\n",
    "    path = os.path.join(os.environ['SAMPLES_PATH'], f\"image_ratio_based_{epoch}.jpg\")\n",
    "    im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create batches of images from directory\n",
    "\n",
    "def create_batches(images, batch_size=BATCH_SIZE):\n",
    "    while True:\n",
    "        for i in range(0, MAX_SIZE, batch_size):\n",
    "            batch_images = image_files[i:i+batch_size]\n",
    "            batch = np.array([imread(file_name) for file_name in batch_images])\n",
    "            batch = (batch.astype(np.float32) - 127.5) / 127.5\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoint(generator, discriminator,epoch):\n",
    "    path = os.path.join(os.environ['CHECKPOINT_PATH'], f\"generator_ratio_based_{epoch}.h5\")\n",
    "    generator.save(path)\n",
    "\n",
    "    path = os.path.join(os.environ['CHECKPOINT_PATH'], f\"discriminator_ratio_based_{epoch}.h5\")\n",
    "    discriminator.save(path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = np.ones((BATCH_SIZE, 1))\n",
    "fake = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "discriminator_loss = []\n",
    "discriminator_accuracy = []\n",
    "generator_loss = []\n",
    "\n",
    "image_files = np.array(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapeModel = tf.keras.Sequential([layers.Resizing(128,128, input_shape=(218,178,3,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Epoch 1 -----------\n",
      "Discriminator loss: 7.410382568195928e-05   Accuracy: 1.0\n",
      "Generator loss: 5.486060763360001e-05\n",
      "---------------------------------------\n",
      "----------- Epoch 2 -----------\n",
      "Discriminator loss: 4.977773187420098e-05   Accuracy: 1.0\n",
      "Generator loss: 0.001680504996329546\n",
      "---------------------------------------\n",
      "----------- Epoch 3 -----------\n",
      "Discriminator loss: 2.9297684250195744e-05   Accuracy: 1.0\n",
      "Generator loss: 0.00047499805805273354\n",
      "---------------------------------------\n",
      "----------- Epoch 4 -----------\n",
      "Discriminator loss: 2.2938666234040284e-05   Accuracy: 1.0\n",
      "Generator loss: 0.0016072471626102924\n",
      "---------------------------------------\n",
      "----------- Epoch 5 -----------\n",
      "Discriminator loss: 2.7064878395322012e-05   Accuracy: 1.0\n",
      "Generator loss: 0.001281192060559988\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 6 -----------\n",
      "Discriminator loss: 8.878236485543312e-06   Accuracy: 1.0\n",
      "Generator loss: 0.014962909743189812\n",
      "---------------------------------------\n",
      "----------- Epoch 7 -----------\n",
      "Discriminator loss: 1.4425160088649136e-05   Accuracy: 1.0\n",
      "Generator loss: 0.009550407528877258\n",
      "---------------------------------------\n",
      "----------- Epoch 8 -----------\n",
      "Discriminator loss: 0.003042540523127783   Accuracy: 1.0\n",
      "Generator loss: 0.06862960010766983\n",
      "---------------------------------------\n",
      "----------- Epoch 9 -----------\n",
      "Discriminator loss: 0.05815682467073202   Accuracy: 0.984375\n",
      "Generator loss: 1.5429282188415527\n",
      "---------------------------------------\n",
      "----------- Epoch 10 -----------\n",
      "Discriminator loss: 0.0697774589061737   Accuracy: 0.9765625\n",
      "Generator loss: 0.028759919106960297\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 11 -----------\n",
      "Discriminator loss: 0.1785723054276218   Accuracy: 0.96875\n",
      "Generator loss: 12.809358596801758\n",
      "---------------------------------------\n",
      "----------- Epoch 12 -----------\n",
      "Discriminator loss: 0.01807402167469263   Accuracy: 0.9921875\n",
      "Generator loss: 0.9942986369132996\n",
      "---------------------------------------\n",
      "----------- Epoch 13 -----------\n",
      "Discriminator loss: 0.19206625409424305   Accuracy: 0.9375\n",
      "Generator loss: 3.0662765502929688\n",
      "---------------------------------------\n",
      "----------- Epoch 14 -----------\n",
      "Discriminator loss: 0.04907700326293707   Accuracy: 0.9765625\n",
      "Generator loss: 0.2246309220790863\n",
      "---------------------------------------\n",
      "----------- Epoch 15 -----------\n",
      "Discriminator loss: 0.02909162361174822   Accuracy: 0.9921875\n",
      "Generator loss: 0.20392431318759918\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 16 -----------\n",
      "Discriminator loss: 0.1367521658539772   Accuracy: 0.953125\n",
      "Generator loss: 0.13339640200138092\n",
      "---------------------------------------\n",
      "----------- Epoch 17 -----------\n",
      "Discriminator loss: 0.10968229919672012   Accuracy: 0.96875\n",
      "Generator loss: 0.024610202759504318\n",
      "---------------------------------------\n",
      "----------- Epoch 18 -----------\n",
      "Discriminator loss: 0.02482905425131321   Accuracy: 0.9921875\n",
      "Generator loss: 0.2218017280101776\n",
      "---------------------------------------\n",
      "----------- Epoch 19 -----------\n",
      "Discriminator loss: 0.011951853521168232   Accuracy: 1.0\n",
      "Generator loss: 0.9646241068840027\n",
      "---------------------------------------\n",
      "----------- Epoch 20 -----------\n",
      "Discriminator loss: 0.0015273968747351319   Accuracy: 1.0\n",
      "Generator loss: 0.00010435660078655928\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 21 -----------\n",
      "Discriminator loss: 0.0041441361827310175   Accuracy: 1.0\n",
      "Generator loss: 0.004309549927711487\n",
      "---------------------------------------\n",
      "----------- Epoch 22 -----------\n",
      "Discriminator loss: 0.07942215166985989   Accuracy: 0.96875\n",
      "Generator loss: 1.6206698417663574\n",
      "---------------------------------------\n",
      "----------- Epoch 23 -----------\n",
      "Discriminator loss: 0.04093835421372205   Accuracy: 0.984375\n",
      "Generator loss: 0.08201341331005096\n",
      "---------------------------------------\n",
      "----------- Epoch 24 -----------\n",
      "Discriminator loss: 0.04288690397515893   Accuracy: 0.9921875\n",
      "Generator loss: 0.029148925095796585\n",
      "---------------------------------------\n",
      "----------- Epoch 25 -----------\n",
      "Discriminator loss: 0.04284791089594364   Accuracy: 0.9921875\n",
      "Generator loss: 0.12844853103160858\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 26 -----------\n",
      "Discriminator loss: 0.10885009914636612   Accuracy: 0.96875\n",
      "Generator loss: 0.37723469734191895\n",
      "---------------------------------------\n",
      "----------- Epoch 27 -----------\n",
      "Discriminator loss: 0.28194864839315414   Accuracy: 0.8984375\n",
      "Generator loss: 3.3046674728393555\n",
      "---------------------------------------\n",
      "----------- Epoch 28 -----------\n",
      "Discriminator loss: 0.08890612423419952   Accuracy: 0.9765625\n",
      "Generator loss: 1.1135315895080566\n",
      "---------------------------------------\n",
      "----------- Epoch 29 -----------\n",
      "Discriminator loss: 0.030213716439902782   Accuracy: 0.9765625\n",
      "Generator loss: 0.023738142102956772\n",
      "---------------------------------------\n",
      "----------- Epoch 30 -----------\n",
      "Discriminator loss: 0.1251390352845192   Accuracy: 0.9609375\n",
      "Generator loss: 0.44219017028808594\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 31 -----------\n",
      "Discriminator loss: 0.1109493188560009   Accuracy: 0.9765625\n",
      "Generator loss: 0.01016012392938137\n",
      "---------------------------------------\n",
      "----------- Epoch 32 -----------\n",
      "Discriminator loss: 0.04705691896378994   Accuracy: 0.9765625\n",
      "Generator loss: 0.038913141936063766\n",
      "---------------------------------------\n",
      "----------- Epoch 33 -----------\n",
      "Discriminator loss: 0.08828268200159073   Accuracy: 0.96875\n",
      "Generator loss: 4.207588195800781\n",
      "---------------------------------------\n",
      "----------- Epoch 34 -----------\n",
      "Discriminator loss: 0.002322918240679428   Accuracy: 1.0\n",
      "Generator loss: 0.0005437920335680246\n",
      "---------------------------------------\n",
      "----------- Epoch 35 -----------\n",
      "Discriminator loss: 0.0019198146492271917   Accuracy: 1.0\n",
      "Generator loss: 0.045054130256175995\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 36 -----------\n",
      "Discriminator loss: 0.022482307977043092   Accuracy: 0.9921875\n",
      "Generator loss: 0.03530171141028404\n",
      "---------------------------------------\n",
      "----------- Epoch 37 -----------\n",
      "Discriminator loss: 0.008676464203745127   Accuracy: 1.0\n",
      "Generator loss: 0.0002356578188482672\n",
      "---------------------------------------\n",
      "----------- Epoch 38 -----------\n",
      "Discriminator loss: 0.028087985701858997   Accuracy: 0.984375\n",
      "Generator loss: 0.06894417852163315\n",
      "---------------------------------------\n",
      "----------- Epoch 39 -----------\n",
      "Discriminator loss: 0.02625106553750811   Accuracy: 0.984375\n",
      "Generator loss: 0.0015208139084279537\n",
      "---------------------------------------\n",
      "----------- Epoch 40 -----------\n",
      "Discriminator loss: 0.012010474980343133   Accuracy: 1.0\n",
      "Generator loss: 0.03647442162036896\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 41 -----------\n",
      "Discriminator loss: 0.023119596764445305   Accuracy: 0.9921875\n",
      "Generator loss: 0.006559095811098814\n",
      "---------------------------------------\n",
      "----------- Epoch 42 -----------\n",
      "Discriminator loss: 0.002193683525547385   Accuracy: 1.0\n",
      "Generator loss: 0.002440560609102249\n",
      "---------------------------------------\n",
      "----------- Epoch 43 -----------\n",
      "Discriminator loss: 0.006224421551451087   Accuracy: 1.0\n",
      "Generator loss: 0.05029291659593582\n",
      "---------------------------------------\n",
      "----------- Epoch 44 -----------\n",
      "Discriminator loss: 0.29361406608950347   Accuracy: 0.90625\n",
      "Generator loss: 2.1137852668762207\n",
      "---------------------------------------\n",
      "----------- Epoch 45 -----------\n",
      "Discriminator loss: 0.03803050983697176   Accuracy: 1.0\n",
      "Generator loss: 0.3807430863380432\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 46 -----------\n",
      "Discriminator loss: 0.026637201197445393   Accuracy: 0.984375\n",
      "Generator loss: 0.028765501454472542\n",
      "---------------------------------------\n",
      "----------- Epoch 47 -----------\n",
      "Discriminator loss: 0.01921847276389599   Accuracy: 0.9921875\n",
      "Generator loss: 0.020460132509469986\n",
      "---------------------------------------\n",
      "----------- Epoch 48 -----------\n",
      "Discriminator loss: 0.03102428838610649   Accuracy: 1.0\n",
      "Generator loss: 0.0926429033279419\n",
      "---------------------------------------\n",
      "----------- Epoch 49 -----------\n",
      "Discriminator loss: 0.02878404654620681   Accuracy: 0.9765625\n",
      "Generator loss: 4.043770786665846e-06\n",
      "---------------------------------------\n",
      "----------- Epoch 50 -----------\n",
      "Discriminator loss: 0.014574583619832993   Accuracy: 0.9921875\n",
      "Generator loss: 0.2263772189617157\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 51 -----------\n",
      "Discriminator loss: 0.036323041655123234   Accuracy: 0.984375\n",
      "Generator loss: 0.2514214515686035\n",
      "---------------------------------------\n",
      "----------- Epoch 52 -----------\n",
      "Discriminator loss: 0.015921877813525498   Accuracy: 1.0\n",
      "Generator loss: 0.002943766536191106\n",
      "---------------------------------------\n",
      "----------- Epoch 53 -----------\n",
      "Discriminator loss: 0.05704578850418329   Accuracy: 0.9765625\n",
      "Generator loss: 0.272629052400589\n",
      "---------------------------------------\n",
      "----------- Epoch 54 -----------\n",
      "Discriminator loss: 0.13732744008302689   Accuracy: 0.9609375\n",
      "Generator loss: 1.9260584115982056\n",
      "---------------------------------------\n",
      "----------- Epoch 55 -----------\n",
      "Discriminator loss: 0.021683859638869762   Accuracy: 0.9921875\n",
      "Generator loss: 0.3578017055988312\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 56 -----------\n",
      "Discriminator loss: 0.02954672835767269   Accuracy: 1.0\n",
      "Generator loss: 0.027304433286190033\n",
      "---------------------------------------\n",
      "----------- Epoch 57 -----------\n",
      "Discriminator loss: 0.44927626592107117   Accuracy: 0.7734375\n",
      "Generator loss: 5.125149250030518\n",
      "---------------------------------------\n",
      "----------- Epoch 58 -----------\n",
      "Discriminator loss: 0.011902489699423313   Accuracy: 1.0\n",
      "Generator loss: 0.038769759237766266\n",
      "---------------------------------------\n",
      "----------- Epoch 59 -----------\n",
      "Discriminator loss: 0.07422854751348495   Accuracy: 0.9765625\n",
      "Generator loss: 0.0831720158457756\n",
      "---------------------------------------\n",
      "----------- Epoch 60 -----------\n",
      "Discriminator loss: 0.045733073726296425   Accuracy: 0.9921875\n",
      "Generator loss: 0.10094594955444336\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 61 -----------\n",
      "Discriminator loss: 0.1493230164051056   Accuracy: 0.9453125\n",
      "Generator loss: 0.7718440294265747\n",
      "---------------------------------------\n",
      "----------- Epoch 62 -----------\n",
      "Discriminator loss: 0.0988537110388279   Accuracy: 0.9609375\n",
      "Generator loss: 4.017443656921387\n",
      "---------------------------------------\n",
      "----------- Epoch 63 -----------\n",
      "Discriminator loss: 0.0856545940041542   Accuracy: 0.96875\n",
      "Generator loss: 0.8195878267288208\n",
      "---------------------------------------\n",
      "----------- Epoch 64 -----------\n",
      "Discriminator loss: 0.33845964074134827   Accuracy: 0.8671875\n",
      "Generator loss: 0.05834042653441429\n",
      "---------------------------------------\n",
      "----------- Epoch 65 -----------\n",
      "Discriminator loss: 0.1279454603791237   Accuracy: 0.984375\n",
      "Generator loss: 0.6721308827400208\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 66 -----------\n",
      "Discriminator loss: 0.24256907403469086   Accuracy: 0.9375\n",
      "Generator loss: 3.664263963699341\n",
      "---------------------------------------\n",
      "----------- Epoch 67 -----------\n",
      "Discriminator loss: 0.20105215907096863   Accuracy: 0.9375\n",
      "Generator loss: 0.056314900517463684\n",
      "---------------------------------------\n",
      "----------- Epoch 68 -----------\n",
      "Discriminator loss: 0.034948498010635376   Accuracy: 0.9921875\n",
      "Generator loss: 0.3335414528846741\n",
      "---------------------------------------\n",
      "----------- Epoch 69 -----------\n",
      "Discriminator loss: 0.13115622103214264   Accuracy: 0.953125\n",
      "Generator loss: 0.6979243159294128\n",
      "---------------------------------------\n",
      "----------- Epoch 70 -----------\n",
      "Discriminator loss: 0.09979584068059921   Accuracy: 0.9765625\n",
      "Generator loss: 0.7663469314575195\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 71 -----------\n",
      "Discriminator loss: 0.04033393459394574   Accuracy: 0.96875\n",
      "Generator loss: 0.0686362162232399\n",
      "---------------------------------------\n",
      "----------- Epoch 72 -----------\n",
      "Discriminator loss: 0.05503141134977341   Accuracy: 0.9921875\n",
      "Generator loss: 0.21776528656482697\n",
      "---------------------------------------\n",
      "----------- Epoch 73 -----------\n",
      "Discriminator loss: 0.004492605978157371   Accuracy: 1.0\n",
      "Generator loss: 0.03840629756450653\n",
      "---------------------------------------\n",
      "----------- Epoch 74 -----------\n",
      "Discriminator loss: 0.13785741105675697   Accuracy: 0.9609375\n",
      "Generator loss: 0.27303850650787354\n",
      "---------------------------------------\n",
      "----------- Epoch 75 -----------\n",
      "Discriminator loss: 0.024213311029598117   Accuracy: 1.0\n",
      "Generator loss: 0.37741321325302124\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 76 -----------\n",
      "Discriminator loss: 0.20008304715156555   Accuracy: 0.9140625\n",
      "Generator loss: 2.41213059425354\n",
      "---------------------------------------\n",
      "----------- Epoch 77 -----------\n",
      "Discriminator loss: 0.03740905225276947   Accuracy: 0.984375\n",
      "Generator loss: 0.42495495080947876\n",
      "---------------------------------------\n",
      "----------- Epoch 78 -----------\n",
      "Discriminator loss: 0.05718149244785309   Accuracy: 0.9921875\n",
      "Generator loss: 0.049252793192863464\n",
      "---------------------------------------\n",
      "----------- Epoch 79 -----------\n",
      "Discriminator loss: 0.11990443244576454   Accuracy: 0.96875\n",
      "Generator loss: 8.535942077636719\n",
      "---------------------------------------\n",
      "----------- Epoch 80 -----------\n",
      "Discriminator loss: 0.056991852819919586   Accuracy: 0.9765625\n",
      "Generator loss: 3.741755962371826\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 81 -----------\n",
      "Discriminator loss: 0.07756072888150811   Accuracy: 0.96875\n",
      "Generator loss: 0.03917224705219269\n",
      "---------------------------------------\n",
      "----------- Epoch 82 -----------\n",
      "Discriminator loss: 0.04568749899044633   Accuracy: 0.984375\n",
      "Generator loss: 0.10898584872484207\n",
      "---------------------------------------\n",
      "----------- Epoch 83 -----------\n",
      "Discriminator loss: 0.03185652941465378   Accuracy: 1.0\n",
      "Generator loss: 0.3173085153102875\n",
      "---------------------------------------\n",
      "----------- Epoch 84 -----------\n",
      "Discriminator loss: 0.09066363889724016   Accuracy: 0.9609375\n",
      "Generator loss: 1.2493445873260498\n",
      "---------------------------------------\n",
      "----------- Epoch 85 -----------\n",
      "Discriminator loss: 0.03424728102982044   Accuracy: 0.984375\n",
      "Generator loss: 0.037497229874134064\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 86 -----------\n",
      "Discriminator loss: 0.048821778036653996   Accuracy: 0.984375\n",
      "Generator loss: 0.1521122306585312\n",
      "---------------------------------------\n",
      "----------- Epoch 87 -----------\n",
      "Discriminator loss: 0.007350703235715628   Accuracy: 1.0\n",
      "Generator loss: 0.09454315900802612\n",
      "---------------------------------------\n",
      "----------- Epoch 88 -----------\n",
      "Discriminator loss: 0.022239900194108486   Accuracy: 1.0\n",
      "Generator loss: 0.15391048789024353\n",
      "---------------------------------------\n",
      "----------- Epoch 89 -----------\n",
      "Discriminator loss: 0.017853446304798126   Accuracy: 1.0\n",
      "Generator loss: 0.17727656662464142\n",
      "---------------------------------------\n",
      "----------- Epoch 90 -----------\n",
      "Discriminator loss: 0.1232050210237503   Accuracy: 0.9609375\n",
      "Generator loss: 0.08704806864261627\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 91 -----------\n",
      "Discriminator loss: 0.00253980525303632   Accuracy: 1.0\n",
      "Generator loss: 0.009600479155778885\n",
      "---------------------------------------\n",
      "----------- Epoch 92 -----------\n",
      "Discriminator loss: 0.08951907977461815   Accuracy: 0.96875\n",
      "Generator loss: 0.2254083752632141\n",
      "---------------------------------------\n",
      "----------- Epoch 93 -----------\n",
      "Discriminator loss: 0.042032888159155846   Accuracy: 0.9921875\n",
      "Generator loss: 2.55718994140625\n",
      "---------------------------------------\n",
      "----------- Epoch 94 -----------\n",
      "Discriminator loss: 0.08594203740358353   Accuracy: 0.9765625\n",
      "Generator loss: 0.3474019169807434\n",
      "---------------------------------------\n",
      "----------- Epoch 95 -----------\n",
      "Discriminator loss: 0.05482079740613699   Accuracy: 0.984375\n",
      "Generator loss: 0.13239148259162903\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "----------- Epoch 96 -----------\n",
      "Discriminator loss: 0.041087547317147255   Accuracy: 1.0\n",
      "Generator loss: 0.3332884907722473\n",
      "---------------------------------------\n",
      "----------- Epoch 97 -----------\n",
      "Discriminator loss: 0.14361678063869476   Accuracy: 0.953125\n",
      "Generator loss: 1.6490137577056885\n",
      "---------------------------------------\n",
      "----------- Epoch 98 -----------\n",
      "Discriminator loss: 0.03670743014663458   Accuracy: 0.9921875\n",
      "Generator loss: 0.9580779671669006\n",
      "---------------------------------------\n",
      "----------- Epoch 99 -----------\n",
      "Discriminator loss: 0.08382023498415947   Accuracy: 0.9765625\n",
      "Generator loss: 0.26582950353622437\n",
      "---------------------------------------\n",
      "----------- Epoch 100 -----------\n",
      "Discriminator loss: 0.016691621858626604   Accuracy: 0.9921875\n",
      "Generator loss: 4.554646968841553\n",
      "---------------------------------------\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f\"----------- Epoch {epoch+1} -----------\")\n",
    "\n",
    "    epoch_images = np.random.choice(image_files, int(MAX_SIZE*RANDOM_SELECT), replace=False)\n",
    "\n",
    "    imgGenerator = create_batches(epoch_images)\n",
    "\n",
    "    discriminator_batch_loss = []\n",
    "    discriminator_batch_acc = []\n",
    "    generator_batch_loss = []\n",
    "\n",
    "    for i in range (len(epoch_images)//BATCH_SIZE):\n",
    "\n",
    "        imgs = next(imgGenerator)\n",
    "        imgs = reshapeModel(imgs)\n",
    "\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
    "\n",
    "        discriminator.trainable = discriminator_train(epoch+1)\n",
    "\n",
    "        gen_imgs = generator.predict(noise, verbose=0)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        g_loss = combined.train_on_batch(noise, real)\n",
    "\n",
    "        discriminator_batch_loss.append(d_loss[0])\n",
    "        generator_batch_loss.append(g_loss)\n",
    "        discriminator_batch_acc.append(d_loss[1])\n",
    "\n",
    "    discriminator_loss.append(np.mean(discriminator_batch_loss))\n",
    "    generator_loss.append(np.mean(generator_batch_loss))\n",
    "    discriminator_accuracy.append(np.mean(discriminator_batch_acc))\n",
    "\n",
    "\n",
    "    print(f\"Discriminator loss: {discriminator_loss[epoch]}   Accuracy: {discriminator_accuracy[epoch]}\")\n",
    "    print(f\"Generator loss: {generator_loss[epoch]}\")\n",
    "    print('---------------------------------------')\n",
    "\n",
    "    if((epoch+1) % INTERVAL==0):\n",
    "        sample_image(epoch+1)\n",
    "        create_checkpoint(generator, discriminator, epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot loss and accuracy\n",
    "\n",
    "plt.plot(discriminator_loss, label='Discriminator loss')\n",
    "plt.plot(discriminator_accuracy, label='Discriminator accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c86d1f08c8747f65d29efdac2337fb2fbe4a38445ea9d06a150195f44de4365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
